# MoltBot Environment Variables
# Copy to .env and configure for your deployment

# =============================================================================
# REQUIRED
# =============================================================================

# Gateway authentication token (REQUIRED)
# Generate a secure random string: openssl rand -hex 32
# Both frontend and backend MUST use the same value
GATEWAY_TOKEN=

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

# Server port (Coolify sets this automatically)
PORT=3000

# Internal gateway port (do not change unless necessary)
GATEWAY_PORT=8001

# Node environment
NODE_ENV=production

# =============================================================================
# LLM CONFIGURATION (IMPORTANT - read carefully!)
# =============================================================================

# Default LLM provider: groq | openrouter | ollama | anthropic | openai | google
# Groq recommended for speed and cost. Claude is fallback only.
DEFAULT_LLM_PROVIDER=groq

# Default model for the provider
# Groq: llama-3.1-8b-instant (fast), llama-3.3-70b-versatile (smart)
# OpenRouter: meta-llama/llama-3.1-8b-instruct, deepseek/deepseek-chat
# Ollama: llama3, mistral, codellama
DEFAULT_MODEL=llama-3.1-8b-instant

# Streaming mode: true | false
# IMPORTANT: Set to false for Groq/OpenRouter/Ollama to prevent stuck requests
# Only enable streaming (true) for Claude if you need real-time token output
LLM_STREAMING=false

# Request timeout in milliseconds (default: 15000 = 15 seconds)
# Prevents stuck/hanging requests. Increase only if needed for slow models.
LLM_REQUEST_TIMEOUT_MS=15000

# Max retries on failure (default: 1)
# Set to 0 for fail-fast behavior
LLM_MAX_RETRIES=1

# =============================================================================
# LLM PROVIDER API KEYS (configure at least one)
# =============================================================================

# ----- GROQ (Recommended - fast & cheap) -----
# Get your free key at: https://console.groq.com/keys
# Supports: llama, mixtral, deepseek models
GROQ_API_KEY=

# ----- OPENROUTER (Many models, pay-per-use) -----
# Get your key at: https://openrouter.ai/keys
# Supports: llama, qwen, deepseek, mixtral, and many more
OPENROUTER_API_KEY=

# ----- OPENAI-COMPATIBLE OVERRIDE -----
# Use these to point to any OpenAI-compatible API (Groq, OpenRouter, vLLM, etc.)
# If set, OPENAI_API_KEY is used for authentication
OPENAI_BASE_URL=
OPENAI_API_KEY=

# ----- ANTHROPIC (Claude) - fallback only -----
# Get your key at: https://console.anthropic.com/
# Note: Expensive. Use as fallback, not primary.
ANTHROPIC_API_KEY=

# ----- GOOGLE AI (Gemini) -----
# Get your key at: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=

# ----- MOONSHOT/KIMI -----
# Get your key at: https://platform.moonshot.cn/
MOONSHOT_API_KEY=
KIMI_API_KEY=

# =============================================================================
# LOCAL LLM (Ollama)
# =============================================================================

# Ollama server URL (must include /v1 suffix for OpenAI-compatible API)
OLLAMA_BASE_URL=http://localhost:11434/v1

# Ollama model to use (must be pulled first: ollama pull llama3)
OLLAMA_MODEL=llama3

# =============================================================================
# SECURITY (Cybersecurity Defense System)
# =============================================================================

# ----- Firewall (Mini-WAF) -----
# Enable/disable request firewall (default: true)
SECURITY_FIREWALL=true

# Enable strict mode for additional header validation
SECURITY_STRICT_MODE=false

# Max payload size in bytes (default: 1MB)
MAX_PAYLOAD_SIZE_BYTES=1048576

# ----- Rate Limiting -----
# API requests per minute per IP (default: 60)
RATE_LIMIT_API_PER_MINUTE=60

# Login attempts per hour per IP (default: 5)
RATE_LIMIT_LOGIN_PER_HOUR=5

# Max WebSocket connections per IP (default: 3)
RATE_LIMIT_WS_PER_IP=3

# Auto-block duration in ms (default: 30 minutes)
AUTO_BLOCK_DURATION_MS=1800000

# Max failed auth attempts before auto-block (default: 5)
MAX_FAILED_AUTH_ATTEMPTS=5

# ----- Gateway Protection -----
# Require password in addition to token
GATEWAY_PASSWORD_REQUIRED=false
GATEWAY_PASSWORD=

# Max total gateway connections (default: 1000)
GATEWAY_MAX_CONNECTIONS=1000

# Connection timeout in ms (default: 30s)
GATEWAY_CONNECTION_TIMEOUT_MS=30000

# ----- Lockdown Mode -----
# Enable lockdown mode (admin-only access)
SECURITY_LOCKDOWN=false

# Admin email for lockdown override
SECURITY_ADMIN_EMAIL=

# Emergency mode (maximum restrictions)
SECURITY_EMERGENCY=false

# Feature-specific lockdown flags
SECURITY_ADMIN_ONLY=false
SECURITY_CHAT_DISABLED=false
SECURITY_TOOLS_DISABLED=false
SECURITY_GATEWAY_RESTRICTED=false

# ----- Kill Switch -----
# Immediately disable all tool execution
KILL_SWITCH=false

# Confirmation code for deactivating kill switch
KILL_SWITCH_CONFIRM_CODE=CONFIRM_DEACTIVATE

# =============================================================================
# ADVANCED
# =============================================================================

# Trusted proxy IPs for X-Forwarded-* headers
TRUSTED_PROXIES=127.0.0.1,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16

# Enable debug mode (NOT recommended in production)
DEBUG=false
