{
  "gateway": {
    "mode": "local",
    "bind": "lan",
    "port": 8001,
    "controlUi": {
      "enabled": true,
      "allowInsecureAuth": true
    },
    "trustedProxies": [
      "0.0.0.0/0",
      "127.0.0.1",
      "10.0.0.0/8",
      "172.16.0.0/12",
      "192.168.0.0/16"
    ]
  },
  "models": {
    "mode": "merge",
    "providers": {
      "moonshot": {
        "baseUrl": "https://api.moonshot.cn/v1",
        "api": "openai-completions",
        "models": [
          {
            "id": "kimi-k2.5",
            "name": "ðŸ¥‡ Kimi K2.5 (LEAD)",
            "reasoning": true,
            "input": ["text", "image"],
            "cost": { "input": 0.5, "output": 2.0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 256000,
            "maxTokens": 8192
          }
        ]
      },
      "anthropic": {
        "baseUrl": "https://api.anthropic.com/v1",
        "api": "anthropic-messages",
        "models": [
          {
            "id": "claude-3-opus-20240229",
            "name": "ðŸ¥ˆ Claude 3 Opus (Premium)",
            "reasoning": true,
            "input": ["text", "image"],
            "cost": { "input": 15.0, "output": 75.0, "cacheRead": 1.50, "cacheWrite": 18.75 },
            "contextWindow": 200000,
            "maxTokens": 4096
          },
          {
            "id": "claude-3-5-sonnet-20241022",
            "name": "Claude 3.5 Sonnet",
            "reasoning": false,
            "input": ["text", "image"],
            "cost": { "input": 3.0, "output": 15.0, "cacheRead": 0.30, "cacheWrite": 3.75 },
            "contextWindow": 200000,
            "maxTokens": 1024
          },
          {
            "id": "claude-3-haiku-20240307",
            "name": "Claude 3 Haiku",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.25, "output": 1.25, "cacheRead": 0.03, "cacheWrite": 0.30 },
            "contextWindow": 200000,
            "maxTokens": 1024
          }
        ]
      },
      "openrouter": {
        "baseUrl": "https://openrouter.ai/api/v1",
        "api": "openai-completions",
        "headers": {
          "HTTP-Referer": "https://moltbot.local",
          "X-Title": "Moltbot"
        },
        "models": [
          {
            "id": "anthropic/claude-3-opus",
            "name": "ðŸ¥‰ Claude 3 Opus (OR)",
            "reasoning": true,
            "input": ["text", "image"],
            "cost": { "input": 15.0, "output": 75.0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 200000,
            "maxTokens": 4096
          },
          {
            "id": "deepseek/deepseek-r1",
            "name": "DeepSeek R1 (Reasoning)",
            "reasoning": true,
            "input": ["text"],
            "cost": { "input": 0.55, "output": 2.19, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 65536,
            "maxTokens": 800
          },
          {
            "id": "deepseek/deepseek-chat",
            "name": "DeepSeek Chat V3",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.14, "output": 0.28, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 65536,
            "maxTokens": 700
          },
          {
            "id": "01-ai/yi-lightning",
            "name": "Yi Lightning (Long Context)",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 1000000,
            "maxTokens": 700
          },
          {
            "id": "qwen/qwen-2.5-72b-instruct",
            "name": "Qwen 2.5 72B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.35, "output": 0.40, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 700
          },
          {
            "id": "qwen/qwen-2.5-32b-instruct",
            "name": "Qwen 2.5 32B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.10, "output": 0.10, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 700
          },
          {
            "id": "meta-llama/llama-3.3-70b-instruct",
            "name": "Llama 3.3 70B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.35, "output": 0.40, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 700
          },
          {
            "id": "meta-llama/llama-3.1-70b-instruct",
            "name": "Llama 3.1 70B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.35, "output": 0.40, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 700
          },
          {
            "id": "meta-llama/llama-3.1-8b-instruct",
            "name": "Llama 3.1 8B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.06, "output": 0.06, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 600
          },
          {
            "id": "mistralai/mixtral-8x22b-instruct",
            "name": "Mixtral 8x22B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.65, "output": 0.65, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 65536,
            "maxTokens": 700
          },
          {
            "id": "mistralai/mixtral-8x7b-instruct",
            "name": "Mixtral 8x7B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.24, "output": 0.24, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 32768,
            "maxTokens": 600
          },
          {
            "id": "mistralai/mistral-7b-instruct",
            "name": "Mistral 7B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.06, "output": 0.06, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 32768,
            "maxTokens": 600
          },
          {
            "id": "google/gemini-2.0-flash-001",
            "name": "Gemini 2.0 Flash",
            "reasoning": false,
            "input": ["text", "image"],
            "cost": { "input": 0.10, "output": 0.40, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 1000000,
            "maxTokens": 8192
          },
          {
            "id": "nvidia/llama-3.1-nemotron-70b-instruct",
            "name": "Nemotron 70B (Reasoning)",
            "reasoning": true,
            "input": ["text"],
            "cost": { "input": 0.35, "output": 0.40, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 4096
          }
        ]
      },
      "groq": {
        "baseUrl": "https://api.groq.com/openai/v1",
        "api": "openai-completions",
        "models": [
          {
            "id": "llama-3.1-8b-instant",
            "name": "Llama 3.1 8B Instant",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.05, "output": 0.08, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 512
          },
          {
            "id": "llama-3.3-70b-versatile",
            "name": "Llama 3.3 70B Versatile",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.59, "output": 0.79, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 512
          },
          {
            "id": "mixtral-8x7b-32768",
            "name": "Mixtral 8x7B",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.24, "output": 0.24, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 32768,
            "maxTokens": 512
          },
          {
            "id": "deepseek-r1-distill-llama-70b",
            "name": "DeepSeek R1 Distill 70B",
            "reasoning": true,
            "input": ["text"],
            "cost": { "input": 0.75, "output": 0.99, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 512
          }
        ]
      },
      "ollama": {
        "baseUrl": "http://localhost:11434/v1",
        "api": "openai-completions",
        "models": [
          {
            "id": "llama3",
            "name": "Llama 3",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 8192,
            "maxTokens": 384
          },
          {
            "id": "llama3.2",
            "name": "Llama 3.2",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 384
          },
          {
            "id": "mistral",
            "name": "Mistral 7B",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 8192,
            "maxTokens": 384
          },
          {
            "id": "deepseek-r1:8b",
            "name": "DeepSeek R1 8B",
            "reasoning": true,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 65536,
            "maxTokens": 384
          }
        ]
      }
    }
  }
}
