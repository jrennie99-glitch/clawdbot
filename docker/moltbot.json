{
  "gateway": {
    "mode": "local",
    "bind": "lan",
    "port": 8001,
    "controlUi": {
      "enabled": true,
      "allowInsecureAuth": true
    },
    "trustedProxies": [
      "127.0.0.1",
      "10.0.0.0/8",
      "172.16.0.0/12",
      "192.168.0.0/16"
    ]
  },
  "agents": {
    "presets": {
      "openrouter_top": {
        "name": "OpenRouter Top Open Models",
        "description": "Best open-source and open-weight models via OpenRouter (no Claude required)",
        "provider": "openrouter",
        "model": "deepseek/deepseek-r1",
        "fallbacks": [
          { "provider": "openrouter", "model": "01-ai/yi-lightning" },
          { "provider": "openrouter", "model": "qwen/qwen-2.5-72b-instruct" },
          { "provider": "openrouter", "model": "meta-llama/llama-3.3-70b-instruct" },
          { "provider": "openrouter", "model": "mistralai/mixtral-8x22b-instruct" },
          { "provider": "openrouter", "model": "meta-llama/llama-3.1-8b-instruct" }
        ],
        "limits": {
          "maxTokens": 700,
          "temperature": 0.7,
          "streaming": false
        }
      },
      "openrouter_reasoning": {
        "name": "OpenRouter Reasoning Models",
        "description": "Best reasoning models for complex tasks",
        "provider": "openrouter",
        "model": "deepseek/deepseek-r1",
        "fallbacks": [
          { "provider": "openrouter", "model": "deepseek/deepseek-chat" },
          { "provider": "openrouter", "model": "qwen/qwen-2.5-72b-instruct" }
        ],
        "limits": {
          "maxTokens": 800,
          "temperature": 0.5
        }
      },
      "openrouter_long_context": {
        "name": "OpenRouter Long Context",
        "description": "Models with large context windows",
        "provider": "openrouter",
        "model": "01-ai/yi-lightning",
        "fallbacks": [
          { "provider": "openrouter", "model": "qwen/qwen-2.5-72b-instruct" },
          { "provider": "openrouter", "model": "meta-llama/llama-3.3-70b-instruct" }
        ],
        "limits": {
          "maxTokens": 700,
          "temperature": 0.7
        }
      },
      "openrouter_fast": {
        "name": "OpenRouter Fast",
        "description": "Fastest available open models",
        "provider": "openrouter",
        "model": "meta-llama/llama-3.1-8b-instruct",
        "fallbacks": [
          { "provider": "openrouter", "model": "mistralai/mistral-7b-instruct" }
        ],
        "limits": {
          "maxTokens": 600,
          "temperature": 0.7
        }
      },
      "groq_primary": {
        "name": "Groq Primary (Legacy)",
        "description": "Original Groq-first setup (legacy compatibility)",
        "provider": "groq",
        "model": "llama-3.1-8b-instant",
        "fallbacks": [
          { "provider": "openrouter", "model": "meta-llama/llama-3.1-8b-instruct" },
          { "provider": "ollama", "model": "llama3" }
        ]
      }
    },
    "model_groups": {
      "reasoning": {
        "description": "Best reasoning and coding models",
        "models": [
          "deepseek/deepseek-r1",
          "deepseek/deepseek-chat",
          "qwen/qwen-2.5-72b-instruct",
          "meta-llama/llama-3.3-70b-instruct"
        ]
      },
      "long_context": {
        "description": "Large context window models",
        "models": [
          "01-ai/yi-lightning",
          "qwen/qwen-2.5-72b-instruct",
          "meta-llama/llama-3.3-70b-instruct"
        ]
      },
      "general": {
        "description": "Stable general-purpose models",
        "models": [
          "meta-llama/llama-3.3-70b-instruct",
          "meta-llama/llama-3.1-70b-instruct",
          "mistralai/mixtral-8x22b-instruct",
          "mistralai/mixtral-8x7b-instruct"
        ]
      },
      "fast": {
        "description": "Fast, efficient models",
        "models": [
          "meta-llama/llama-3.1-8b-instruct",
          "mistralai/mistral-7b-instruct"
        ]
      }
    }
  },
  "models": {
    "mode": "merge",
    "providers": {
      "openrouter": {
        "baseUrl": "https://openrouter.ai/api/v1",
        "api": "openai-completions",
        "headers": {
          "HTTP-Referer": "https://moltbot.local",
          "X-Title": "Moltbot"
        },
        "models": [
          {
            "id": "deepseek/deepseek-r1",
            "name": "DeepSeek R1 (Reasoning)",
            "reasoning": true,
            "input": ["text"],
            "cost": { "input": 0.55, "output": 2.19, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 65536,
            "maxTokens": 800
          },
          {
            "id": "deepseek/deepseek-chat",
            "name": "DeepSeek Chat V3",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.14, "output": 0.28, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 65536,
            "maxTokens": 700
          },
          {
            "id": "01-ai/yi-lightning",
            "name": "Yi Lightning (Kimi 2.5)",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 1000000,
            "maxTokens": 700
          },
          {
            "id": "qwen/qwen-2.5-72b-instruct",
            "name": "Qwen 2.5 72B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.35, "output": 0.40, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 700
          },
          {
            "id": "qwen/qwen-2.5-32b-instruct",
            "name": "Qwen 2.5 32B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.10, "output": 0.10, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 700
          },
          {
            "id": "meta-llama/llama-3.3-70b-instruct",
            "name": "Llama 3.3 70B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.35, "output": 0.40, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 700
          },
          {
            "id": "meta-llama/llama-3.1-70b-instruct",
            "name": "Llama 3.1 70B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.35, "output": 0.40, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 700
          },
          {
            "id": "meta-llama/llama-3.1-8b-instruct",
            "name": "Llama 3.1 8B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.06, "output": 0.06, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 600
          },
          {
            "id": "mistralai/mixtral-8x22b-instruct",
            "name": "Mixtral 8x22B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.65, "output": 0.65, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 65536,
            "maxTokens": 700
          },
          {
            "id": "mistralai/mixtral-8x7b-instruct",
            "name": "Mixtral 8x7B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.24, "output": 0.24, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 32768,
            "maxTokens": 600
          },
          {
            "id": "mistralai/mistral-7b-instruct",
            "name": "Mistral 7B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.06, "output": 0.06, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 32768,
            "maxTokens": 600
          }
        ]
      },
      "groq": {
        "baseUrl": "https://api.groq.com/openai/v1",
        "api": "openai-completions",
        "models": [
          {
            "id": "llama-3.1-8b-instant",
            "name": "Llama 3.1 8B Instant",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.05, "output": 0.08, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 512
          },
          {
            "id": "llama-3.3-70b-versatile",
            "name": "Llama 3.3 70B Versatile",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.59, "output": 0.79, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 512
          },
          {
            "id": "mixtral-8x7b-32768",
            "name": "Mixtral 8x7B",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.24, "output": 0.24, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 32768,
            "maxTokens": 512
          },
          {
            "id": "deepseek-r1-distill-llama-70b",
            "name": "DeepSeek R1 Distill 70B",
            "reasoning": true,
            "input": ["text"],
            "cost": { "input": 0.75, "output": 0.99, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 512
          }
        ]
      },
      "ollama": {
        "baseUrl": "http://localhost:11434/v1",
        "api": "openai-completions",
        "models": [
          {
            "id": "llama3",
            "name": "Llama 3",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 8192,
            "maxTokens": 384
          },
          {
            "id": "llama3.2",
            "name": "Llama 3.2",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 384
          },
          {
            "id": "mistral",
            "name": "Mistral 7B",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 8192,
            "maxTokens": 384
          },
          {
            "id": "deepseek-r1:8b",
            "name": "DeepSeek R1 8B",
            "reasoning": true,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 65536,
            "maxTokens": 384
          }
        ]
      },
      "anthropic": {
        "baseUrl": "https://api.anthropic.com/v1",
        "api": "anthropic-messages",
        "models": [
          {
            "id": "claude-3-5-sonnet-20241022",
            "name": "Claude 3.5 Sonnet",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 3.0, "output": 15.0, "cacheRead": 0.30, "cacheWrite": 3.75 },
            "contextWindow": 200000,
            "maxTokens": 1024
          },
          {
            "id": "claude-3-haiku-20240307",
            "name": "Claude 3 Haiku",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.25, "output": 1.25, "cacheRead": 0.03, "cacheWrite": 0.30 },
            "contextWindow": 200000,
            "maxTokens": 1024
          }
        ]
      }
    }
  }
}
