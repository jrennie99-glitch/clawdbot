{
  "gateway": {
    "mode": "local",
    "bind": "lan",
    "port": 8001,
    "controlUi": {
      "enabled": true,
      "allowInsecureAuth": true
    },
    "trustedProxies": [
      "127.0.0.1",
      "10.0.0.0/8",
      "172.16.0.0/12",
      "192.168.0.0/16"
    ]
  },
  "agents": {
    "defaults": {
      "model": {
        "provider": "groq",
        "model": "llama-3.1-8b-instant",
        "fallbacks": [
          { "provider": "openrouter", "model": "meta-llama/llama-3.1-8b-instruct" },
          { "provider": "ollama", "model": "llama3" },
          { "provider": "anthropic", "model": "claude-3-haiku-20240307" }
        ]
      },
      "timeoutMs": 12000,
      "connectionTimeoutMs": 5000,
      "streaming": false,
      "streamingProviders": {
        "groq": false,
        "openrouter": false,
        "ollama": false,
        "vllm": false,
        "moonshot": false,
        "anthropic": true
      },
      "maxTokens": {
        "groq": 512,
        "openrouter": 512,
        "ollama": 384,
        "anthropic": 1024,
        "default": 512
      }
    }
  },
  "models": {
    "mode": "merge",
    "providers": {
      "groq": {
        "baseUrl": "https://api.groq.com/openai/v1",
        "api": "openai-completions",
        "models": [
          {
            "id": "llama-3.1-8b-instant",
            "name": "Llama 3.1 8B Instant",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.05, "output": 0.08, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 512
          },
          {
            "id": "llama-3.3-70b-versatile",
            "name": "Llama 3.3 70B Versatile",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.59, "output": 0.79, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 512
          },
          {
            "id": "mixtral-8x7b-32768",
            "name": "Mixtral 8x7B",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.24, "output": 0.24, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 32768,
            "maxTokens": 512
          },
          {
            "id": "deepseek-r1-distill-llama-70b",
            "name": "DeepSeek R1 Distill 70B",
            "reasoning": true,
            "input": ["text"],
            "cost": { "input": 0.75, "output": 0.99, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 512
          }
        ]
      },
      "openrouter": {
        "baseUrl": "https://openrouter.ai/api/v1",
        "api": "openai-completions",
        "models": [
          {
            "id": "meta-llama/llama-3.1-8b-instruct",
            "name": "Llama 3.1 8B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.06, "output": 0.06, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 512
          },
          {
            "id": "deepseek/deepseek-chat",
            "name": "DeepSeek Chat",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.14, "output": 0.28, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 65536,
            "maxTokens": 512
          },
          {
            "id": "qwen/qwen-2.5-72b-instruct",
            "name": "Qwen 2.5 72B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.35, "output": 0.40, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 512
          },
          {
            "id": "mistralai/mixtral-8x7b-instruct",
            "name": "Mixtral 8x7B Instruct",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0.24, "output": 0.24, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 32768,
            "maxTokens": 512
          }
        ]
      },
      "ollama": {
        "baseUrl": "http://localhost:11434/v1",
        "api": "openai-completions",
        "models": [
          {
            "id": "llama3",
            "name": "Llama 3",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 8192,
            "maxTokens": 384
          },
          {
            "id": "llama3.2",
            "name": "Llama 3.2",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 131072,
            "maxTokens": 384
          },
          {
            "id": "mistral",
            "name": "Mistral 7B",
            "reasoning": false,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 8192,
            "maxTokens": 384
          },
          {
            "id": "deepseek-r1:8b",
            "name": "DeepSeek R1 8B",
            "reasoning": true,
            "input": ["text"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 65536,
            "maxTokens": 384
          }
        ]
      }
    }
  }
}
