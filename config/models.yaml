# Clawdbot Model Configuration
# Lead: Kimi 2.5 (Moonshot)
# Open Source Squad: OpenRouter (Claude-free)

default_model: "kimi-k2.5"

# Automatic task-based routing
task_routing:
  default: "kimi-k2.5"
  
  coding:
    primary: "deepseek/deepseek-coder"
    fallback: "kimi-k2.5"
    
  reasoning:
    primary: "nvidia/llama-3.1-nemotron-70b-instruct"
    fallback: "kimi-k2.5"
    
  creative_writing:
    primary: "meta-llama/llama-3.3-70b-instruct"
    fallback: "kimi-k2.5"
    
  long_context:
    primary: "kimi-k2.5"
    fallback: "google/gemma-2-27b-it"
    
  fast_responses:
    primary: "mistralai/mistral-7b-instruct"
    fallback: "kimi-k2.5"

providers:
  moonshot:
    name: "Moonshot AI"
    base_url: "https://api.moonshot.cn/v1"
    api_key_env: "MOONSHOT_API_KEY"
    models:
      kimi-k2.5:
        id: "kimi-k2.5"
        name: "Kimi K2.5"
        strengths: ["general", "long_context", "chinese", "reasoning"]
        max_tokens: 8192
        context_window: 256000
        
  openrouter:
    name: "OpenRouter"
    base_url: "https://openrouter.ai/api/v1"
    api_key_env: "OPENROUTER_API_KEY"
    models:
      deepseek-coder:
        id: "deepseek/deepseek-coder"
        name: "DeepSeek Coder V2"
        strengths: ["coding", "technical", "math"]
        max_tokens: 8192
        
      nemotron-70b:
        id: "nvidia/llama-3.1-nemotron-70b-instruct"
        name: "Nemotron 70B"
        strengths: ["reasoning", "math", "logic"]
        max_tokens: 4096
        
      llama-3.3-70b:
        id: "meta-llama/llama-3.3-70b-instruct"
        name: "Llama 3.3 70B"
        strengths: ["general", "creative", "instruction_following"]
        max_tokens: 8192
        
      gemma-2-27b:
        id: "google/gemma-2-27b-it"
        name: "Gemma 2 27B"
        strengths: ["efficiency", "safety", "multilingual"]
        max_tokens: 8192
        
      mistral-7b:
        id: "mistralai/mistral-7b-instruct"
        name: "Mistral 7B"
        strengths: ["speed", "simple_tasks", "low_cost"]
        max_tokens: 4096
        
      qwen-2.5-72b:
        id: "qwen/qwen-2.5-72b-instruct"
        name: "Qwen 2.5 72B"
        strengths: ["coding", "chinese", "math"]
        max_tokens: 8192
        
      mixtral-8x22b:
        id: "mistralai/mixtral-8x22b-instruct"
        name: "Mixtral 8x22B"
        strengths: ["complex_reasoning", "knowledge"]
        max_tokens: 4096

auto_switch:
  enabled: true
  detect_task: true
  fallback_to_kimi: true
  cost_optimization: true
